{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multinetwork storage optimization with PandaModels.jl\n",
    "This tutorial describes how to run a storage optimization over multiple timesteps with a PandaModels.jl multinetwork\n",
    "together with pandapower.\n",
    "\n",
    "To run a storage optimization over multiple time steps, the power system data is copied n_timestep times internally.\n",
    "This is done efficiently in a julia script. Each network in the multinetwork dict represents a single time step. \n",
    "The input time series must be written to the loads and generators accordingly to each network. \n",
    "This is currently done by converting input time series to pandapwower controllers, saving it together with the grid data as a json file and loading the data back in julia. This \"hack\" is probably just a temporary solution. \n",
    "\n",
    "Some notes:\n",
    "* only storages which are set as \"controllable\" are optimized\n",
    "* time series can be written to load / sgen elements\n",
    "* output of the optimization is a dict containing pandas DataFrames for every optimized storage and time step   \n",
    "\n",
    "For more details on PowerModels (PandaModels) storage model see:\n",
    "\n",
    "https://lanl-ansi.github.io/PowerModels.jl/stable/storage/ and \n",
    "https://github.com/e2nIEE/PandaModels.jl/blob/develop/src/models/call_powermodels.jl\n",
    "\n",
    "For more details on PowerModels multinetworks see:\n",
    "\n",
    "https://lanl-ansi.github.io/PowerModels.jl/stable/multi-networks/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "You need the standard Julia, PowerModels, Ipopt and JuMP Installation (see the opf_powermodels.ipynb).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the storage optimization\n",
    "In order to start the optimization and visualize results, we follow four steps:\n",
    "1) Load the pandapower grid data (here the cigre MV grid)\n",
    "2) Convert the time series to pandapwoer-controllers\n",
    "3) Start the optimization\n",
    "4) Get and plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1) Get the grid data\n",
    "We load the cigre medium voltage grid with \"pv\" and \"wind\" generators. Also we set some limits and add a storage with\n",
    "**controllable** == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks as nw\n",
    "\n",
    "def cigre_grid():\n",
    "    net = nw.create_cigre_network_mv(\"pv_wind\")\n",
    "    # set some limits\n",
    "    min_vm_pu = 0.95\n",
    "    max_vm_pu = 1.05\n",
    "\n",
    "    net[\"bus\"].loc[:, \"min_vm_pu\"] = min_vm_pu\n",
    "    net[\"bus\"].loc[:, \"max_vm_pu\"] = max_vm_pu\n",
    "\n",
    "    net[\"line\"].loc[:, \"max_loading_percent\"] = 100.\n",
    "\n",
    "    # close all switches\n",
    "    net.switch.loc[:, \"closed\"] = True\n",
    "    # add storage to bus 10\n",
    "    pp.create_storage(net, 10, p_mw=0.5, max_e_mwh=.2, soc_percent=0., q_mvar=0., controllable=True)\n",
    "\n",
    "    return net\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Convert the time series to pandapower-controllers\n",
    "The following functions loads the example time series from the input_file and scales the power accordingly.\n",
    "It then adds the time series data to the grid model by creating controllers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandapower.control import ConstControl\n",
    "from pandapower.timeseries import DFData\n",
    "\n",
    "def convert_timeseries_to_controller(net, input_file):\n",
    "    \n",
    "    # set the load type in the cigre grid, since it is not specified\n",
    "    net[\"load\"].loc[:, \"type\"] = \"residential\"\n",
    "    \n",
    "    # set the sgen type in the cigre grid\n",
    "    net.sgen.loc[:, \"type\"] = \"pv\"\n",
    "    net.sgen.loc[8, \"type\"] = \"wind\"\n",
    "\n",
    "    # read the example time series\n",
    "    time_series = pd.read_json(input_file)\n",
    "    time_series.sort_index(inplace=True)\n",
    "\n",
    "    # this example time series has a 15min resolution with 96 time steps for one day\n",
    "    n_timesteps = time_series.shape[0]\n",
    "    \n",
    "    # get rated power\n",
    "    load_p = net[\"load\"].loc[:, \"p_mw\"].values\n",
    "    sgen_p = net[\"sgen\"].loc[:7, \"p_mw\"].values\n",
    "    wind_p = net[\"sgen\"].loc[8, \"p_mw\"]\n",
    "\n",
    "    load_ts = pd.DataFrame(index=time_series.index.tolist(), columns=net.load.index.tolist())\n",
    "    sgen_ts = pd.DataFrame(index=time_series.index.tolist(), columns=net.sgen.index.tolist())\n",
    "    for t in range(n_timesteps):\n",
    "        load_ts.loc[t] = load_p * time_series.at[t, \"residential\"]\n",
    "        sgen_ts.loc[t][:8] = sgen_p * time_series.at[t, \"pv\"]\n",
    "        sgen_ts.loc[t][8] = wind_p * time_series.at[t, \"wind\"]\n",
    "\n",
    "    # create time series controller for load and sgen \n",
    "    ConstControl(net, element=\"load\", variable=\"p_mw\",\n",
    "                 element_index=net.load.index.tolist(), profile_name=net.load.index.tolist(),\n",
    "                 data_source=DFData(load_ts))\n",
    "    ConstControl(net, element=\"sgen\", variable=\"p_mw\",\n",
    "                 element_index=net.sgen.index.tolist(), profile_name=net.sgen.index.tolist(),\n",
    "                 data_source=DFData(sgen_ts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Start the optimization \n",
    "Before we start the optimization, we create the grid and controller, adding the time series in 15min resolution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# open the cigre mv grid\n",
    "net = cigre_grid()\n",
    "\n",
    "# convert the time series to pandapower controller\n",
    "input_file = \"cigre_timeseries_15min.json\"\n",
    "convert_timeseries_to_controller(net, input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = cigre_grid()\n",
    "input_file = \"cigre_timeseries_15min.json\"\n",
    "\n",
    "    \n",
    "# set the load type in the cigre grid, since it is not specified\n",
    "net[\"load\"].loc[:, \"type\"] = \"residential\"\n",
    "\n",
    "# set the sgen type in the cigre grid\n",
    "net.sgen.loc[:, \"type\"] = \"pv\"\n",
    "net.sgen.loc[8, \"type\"] = \"wind\"\n",
    "\n",
    "# read the example time series\n",
    "time_series = pd.read_json(input_file)\n",
    "time_series.sort_index(inplace=True)\n",
    "\n",
    "# this example time series has a 15min resolution with 96 time steps for one day\n",
    "n_timesteps = time_series.shape[0]\n",
    "\n",
    "# get rated power\n",
    "load_p = net[\"load\"].loc[:, \"p_mw\"].values\n",
    "sgen_p = net[\"sgen\"].loc[:7, \"p_mw\"].values\n",
    "wind_p = net[\"sgen\"].loc[8, \"p_mw\"]\n",
    "\n",
    "load_ts = pd.DataFrame(index=time_series.index.tolist(), columns=net.load.index.tolist())\n",
    "sgen_ts = pd.DataFrame(index=time_series.index.tolist(), columns=net.sgen.index.tolist())\n",
    "\n",
    "n_timesteps\n",
    "sgen_ts.loc[10][8]\n",
    "\n",
    "#for t in range(n_timesteps):\n",
    "#    load_ts.loc[t] = load_p * time_series.at[t, \"residential\"]\n",
    "#    sgen_ts.loc[t][:8] = sgen_p * time_series.at[t, \"pv\"]\n",
    "#    sgen_ts.loc[t][8] = wind_p * time_series.at[t, \"wind\"]\n",
    "\n",
    "# create time series controller for load and sgen \n",
    "#ConstControl(net, element=\"load\", variable=\"p_mw\",\n",
    "#                element_index=net.load.index.tolist(), profile_name=net.load.index.tolist(),\n",
    "#                data_source=DFData(load_ts))\n",
    "#ConstControl(net, element=\"sgen\", variable=\"p_mw\",\n",
    "#                element_index=net.sgen.index.tolist(), profile_name=net.sgen.index.tolist(),\n",
    "#                data_source=DFData(sgen_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the time series is added through (const) controllers, and you can check the created controllers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time series controller: Empty DataFrame\n",
      "Columns: [object, in_service, order, level, initial_run, recycle]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\mnumai200\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\users\\mnumai200\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\mnumai200\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\numair.ai\\GitHub\\pandapower-mn\\tutorials\\pandamodels_storage.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/numair.ai/GitHub/pandapower-mn/tutorials/pandamodels_storage.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--- time series controller:\u001b[39m\u001b[39m\"\u001b[39m, net\u001b[39m.\u001b[39mcontroller)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/numair.ai/GitHub/pandapower-mn/tutorials/pandamodels_storage.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# print time series data in controller\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/numair.ai/GitHub/pandapower-mn/tutorials/pandamodels_storage.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--- considered element of controller 0:\u001b[39m\u001b[39m\"\u001b[39m, net\u001b[39m.\u001b[39;49mcontroller\u001b[39m.\u001b[39;49mobject[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmatching_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39melement\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/numair.ai/GitHub/pandapower-mn/tutorials/pandamodels_storage.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--- considered element index of controller 0:\u001b[39m\u001b[39m\"\u001b[39m,net\u001b[39m.\u001b[39mcontroller\u001b[39m.\u001b[39mobject[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmatching_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39melement_index\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/numair.ai/GitHub/pandapower-mn/tutorials/pandamodels_storage.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--- time series data:\u001b[39m\u001b[39m\"\u001b[39m,net\u001b[39m.\u001b[39mcontroller\u001b[39m.\u001b[39mobject[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdata_source\u001b[39m.\u001b[39mdf)\n",
      "File \u001b[1;32mc:\\users\\mnumai200\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\mnumai200\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\users\\mnumai200\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# print controller\n",
    "print(\"--- time series controller:\", net.controller)\n",
    "\n",
    "# print time series data in controller\n",
    "print(\"--- considered element of controller 0:\", net.controller.object[0].__dict__[\"matching_params\"][\"element\"])\n",
    "print(\"--- considered element index of controller 0:\",net.controller.object[0].__dict__[\"matching_params\"][\"element_index\"])\n",
    "print(\"--- time series data:\",net.controller.object[0].data_source.df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the optimization for timesteps from 0 to 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no costs are given - overall generated power is minimized\n"
     ]
    }
   ],
   "source": [
    "# run the optimization for the first ten timesteps (the first run can be slow.\n",
    "try:\n",
    "    pp.runpm_storage_opf(net, from_time_step=0, to_time_step=10)\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Get and plot the results \n",
    "Get and plot the optimization results for the storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandapower.opf.pm_storage import read_pm_storage_results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_storage_results(storage_results):\n",
    "    n_res = len(storage_results.keys())\n",
    "    fig, axes = plt.subplots(n_res, 2)\n",
    "    if n_res == 1:\n",
    "        axes = [axes]\n",
    "    for i, (key, val) in enumerate(storage_results.items()):\n",
    "        res = val\n",
    "        axes[i][0].set_title(\"Storage {}\".format(key))\n",
    "        el = res.loc[:, [\"p_mw\", \"q_mvar\", \"soc_mwh\"]]\n",
    "        el.plot(ax=axes[i][0])\n",
    "        axes[i][0].set_xlabel(\"time step\")\n",
    "        axes[i][0].legend(loc=4)\n",
    "        axes[i][0].grid()\n",
    "        ax2 = axes[i][1]\n",
    "        patch = plt.plot([], [], ms=8, ls=\"--\", mec=None, color=\"grey\", label=\"{:s}\".format(\"soc_percent\"))\n",
    "        ax2.legend(handles=patch)\n",
    "        ax2.set_label(\"SOC percent\")\n",
    "        res.loc[:, \"soc_percent\"].plot(ax=ax2, linestyle=\"--\", color=\"grey\")\n",
    "        ax2.grid()\n",
    "    plt.show()\n",
    "\n",
    "# get the results\n",
    "#storage_results = read_pm_storage_results(net)    \n",
    "    \n",
    "# plot the results\n",
    "#plot_storage_results(storage_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
